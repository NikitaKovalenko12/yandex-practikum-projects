{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Предсказание цены автомобиля"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Необходимо обучить модель для определения рыночной стоимости автомобиля. В нашем распоряжении следующие данные: технические характеристики, комплектации и цены автомобилей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оглавление:\n",
    "* [1. Подготовка данных](#1)\n",
    "* [2. Обучение моделей](#2)\n",
    "* [3. Анализ моделей](#3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Подготовка данных <a class=\"anchor\" id=\"1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем библиотеки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <импорт библиотеки pandas>\n",
    "import pandas as pd\n",
    "\n",
    "# <импорт библиотеки sklearn>\n",
    "import sklearn\n",
    "\n",
    "# <Отключение предупреждений>\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# <импорт библиотеки numpy>\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прочитаем файл с данными:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <чтение файла с данными с сохранением в переменную df>\n",
    "df = pd.read_csv('/datasets/autos.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим информацию по датафрейму и первые 5 строк:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 354369 entries, 0 to 354368\n",
      "Data columns (total 16 columns):\n",
      "DateCrawled          354369 non-null object\n",
      "Price                354369 non-null int64\n",
      "VehicleType          316879 non-null object\n",
      "RegistrationYear     354369 non-null int64\n",
      "Gearbox              334536 non-null object\n",
      "Power                354369 non-null int64\n",
      "Model                334664 non-null object\n",
      "Kilometer            354369 non-null int64\n",
      "RegistrationMonth    354369 non-null int64\n",
      "FuelType             321474 non-null object\n",
      "Brand                354369 non-null object\n",
      "NotRepaired          283215 non-null object\n",
      "DateCreated          354369 non-null object\n",
      "NumberOfPictures     354369 non-null int64\n",
      "PostalCode           354369 non-null int64\n",
      "LastSeen             354369 non-null object\n",
      "dtypes: int64(7), object(9)\n",
      "memory usage: 43.3+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateCrawled</th>\n",
       "      <th>Price</th>\n",
       "      <th>VehicleType</th>\n",
       "      <th>RegistrationYear</th>\n",
       "      <th>Gearbox</th>\n",
       "      <th>Power</th>\n",
       "      <th>Model</th>\n",
       "      <th>Kilometer</th>\n",
       "      <th>RegistrationMonth</th>\n",
       "      <th>FuelType</th>\n",
       "      <th>Brand</th>\n",
       "      <th>NotRepaired</th>\n",
       "      <th>DateCreated</th>\n",
       "      <th>NumberOfPictures</th>\n",
       "      <th>PostalCode</th>\n",
       "      <th>LastSeen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2016-03-24 11:52:17</td>\n",
       "      <td>480</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1993</td>\n",
       "      <td>manual</td>\n",
       "      <td>0</td>\n",
       "      <td>golf</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>petrol</td>\n",
       "      <td>volkswagen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-03-24 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>70435</td>\n",
       "      <td>2016-04-07 03:16:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2016-03-24 10:58:45</td>\n",
       "      <td>18300</td>\n",
       "      <td>coupe</td>\n",
       "      <td>2011</td>\n",
       "      <td>manual</td>\n",
       "      <td>190</td>\n",
       "      <td>NaN</td>\n",
       "      <td>125000</td>\n",
       "      <td>5</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>audi</td>\n",
       "      <td>yes</td>\n",
       "      <td>2016-03-24 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>66954</td>\n",
       "      <td>2016-04-07 01:46:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2016-03-14 12:52:21</td>\n",
       "      <td>9800</td>\n",
       "      <td>suv</td>\n",
       "      <td>2004</td>\n",
       "      <td>auto</td>\n",
       "      <td>163</td>\n",
       "      <td>grand</td>\n",
       "      <td>125000</td>\n",
       "      <td>8</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>jeep</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-03-14 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>90480</td>\n",
       "      <td>2016-04-05 12:47:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2016-03-17 16:54:04</td>\n",
       "      <td>1500</td>\n",
       "      <td>small</td>\n",
       "      <td>2001</td>\n",
       "      <td>manual</td>\n",
       "      <td>75</td>\n",
       "      <td>golf</td>\n",
       "      <td>150000</td>\n",
       "      <td>6</td>\n",
       "      <td>petrol</td>\n",
       "      <td>volkswagen</td>\n",
       "      <td>no</td>\n",
       "      <td>2016-03-17 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>91074</td>\n",
       "      <td>2016-03-17 17:40:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2016-03-31 17:25:20</td>\n",
       "      <td>3600</td>\n",
       "      <td>small</td>\n",
       "      <td>2008</td>\n",
       "      <td>manual</td>\n",
       "      <td>69</td>\n",
       "      <td>fabia</td>\n",
       "      <td>90000</td>\n",
       "      <td>7</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>skoda</td>\n",
       "      <td>no</td>\n",
       "      <td>2016-03-31 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>60437</td>\n",
       "      <td>2016-04-06 10:17:21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           DateCrawled  Price VehicleType  RegistrationYear Gearbox  Power  \\\n",
       "0  2016-03-24 11:52:17    480         NaN              1993  manual      0   \n",
       "1  2016-03-24 10:58:45  18300       coupe              2011  manual    190   \n",
       "2  2016-03-14 12:52:21   9800         suv              2004    auto    163   \n",
       "3  2016-03-17 16:54:04   1500       small              2001  manual     75   \n",
       "4  2016-03-31 17:25:20   3600       small              2008  manual     69   \n",
       "\n",
       "   Model  Kilometer  RegistrationMonth  FuelType       Brand NotRepaired  \\\n",
       "0   golf     150000                  0    petrol  volkswagen         NaN   \n",
       "1    NaN     125000                  5  gasoline        audi         yes   \n",
       "2  grand     125000                  8  gasoline        jeep         NaN   \n",
       "3   golf     150000                  6    petrol  volkswagen          no   \n",
       "4  fabia      90000                  7  gasoline       skoda          no   \n",
       "\n",
       "           DateCreated  NumberOfPictures  PostalCode             LastSeen  \n",
       "0  2016-03-24 00:00:00                 0       70435  2016-04-07 03:16:57  \n",
       "1  2016-03-24 00:00:00                 0       66954  2016-04-07 01:46:50  \n",
       "2  2016-03-14 00:00:00                 0       90480  2016-04-05 12:47:46  \n",
       "3  2016-03-17 00:00:00                 0       91074  2016-03-17 17:40:17  \n",
       "4  2016-03-31 00:00:00                 0       60437  2016-04-06 10:17:21  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# <рассмотрим датафрейм df_region_0>\n",
    "print(df.info())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подробнее опишем значение каждого атрибута.\n",
    "\n",
    "Признаки\n",
    "\n",
    "* DateCrawled — дата скачивания анкеты из базы\n",
    "* VehicleType — тип автомобильного кузова\n",
    "* RegistrationYear — год регистрации автомобиля\n",
    "* Gearbox — тип коробки передач\n",
    "* Power — мощность (л. с.)\n",
    "* Model — модель автомобиля\n",
    "* Kilometer — пробег (км)\n",
    "* RegistrationMonth — месяц регистрации автомобиля\n",
    "* FuelType — тип топлива\n",
    "* Brand — марка автомобиля\n",
    "* NotRepaired — была машина в ремонте или нет\n",
    "* DateCreated — дата создания анкеты\n",
    "* NumberOfPictures — количество фотографий автомобиля\n",
    "* PostalCode — почтовый индекс владельца анкеты (пользователя)\n",
    "* LastSeen — дата последней активности пользователя\n",
    "\n",
    "Целевой признак\n",
    "\n",
    "* Price — цена (евро)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим отдельный датафрейм, который будем очищать от пропусков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessed=df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сбросим столбцы дат, они не пригодятся для обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <сбросим три столбца, которые не помогут нам предсказать целевой признак>\n",
    "df_preprocessed = df_preprocessed.drop(['DateCrawled','DateCreated','LastSeen'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим столбец *Power*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    354369.000000\n",
       "mean        110.094337\n",
       "std         189.850405\n",
       "min           0.000000\n",
       "25%          69.000000\n",
       "50%         105.000000\n",
       "75%         143.000000\n",
       "max       20000.000000\n",
       "Name: Power, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preprocessed['Power'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим сколько значений столбца *Power* аномальны."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "25.0\n",
      "43.0\n"
     ]
    }
   ],
   "source": [
    "print(df_preprocessed['Power'].quantile(0.11))\n",
    "print(df_preprocessed['Power'].quantile(0.115))\n",
    "print(df_preprocessed['Power'].quantile(0.12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заменим эти значения на медиану."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_median = df_preprocessed[df_preprocessed['Power']>25]['Power'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessed['Power'] = (np.where((df_preprocessed.Power <= 25), \n",
    "                               power_median, \n",
    "                               df_preprocessed.Power))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заполним пропуски в столбце *Model*, опираться будем на бренд и лошадиные силы. Заполним модой - наиболее часто встречающимся значением для определенных группы бренда и кол-ва лошадних сил. Если значения модели нет, будем проставлено значение unknown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessed['Model'] = (df_preprocessed.groupby(['Brand','Power'])['Model'].transform(lambda x: x.fillna((x.mode()[0] if not x.mode().empty else \"unknown\"))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заполним пропуски в столбце *VehicleType*, опираться будем на бренд и модель. Тут мы можем рассчитывать только на заполнение пропусков по моде, так как по имеющимся признакам предположить какой у машины тип кузова мы не в силах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessed['VehicleType'] = (df_preprocessed.groupby(['Brand','Model'])['VehicleType'].transform(lambda x: x.fillna((x.mode()[0] if not x.mode().empty else \"unknown\"))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заполним пропуски в столбце *FuelType*, опираться будем на бренд и модель. Стиль заполнения пропусков тот же."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessed['FuelType'] = (df_preprocessed.groupby(['Brand','Model'])['FuelType'].transform(lambda x: x.fillna((x.mode()[0] if not x.mode().empty else \"unknown\"))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заполним пропуски в столбце *Gearbox*, опираться будем на бренд и модель. Стиль заполнения пропусков тот же."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessed['Gearbox'] = (df_preprocessed.groupby(['Brand','Model'])['Gearbox'].transform(lambda x: x.fillna((x.mode()[0] if not x.mode().empty else \"unknown\"))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим гипотезу:\n",
    "* Средняя цена у автомобилей с признаком *NotRepaired* = *yes* и *NotRepaired* = *nan* различается.\n",
    "\n",
    "Сформулируем гипотезы:\n",
    "\n",
    "**H₀:** Средняя цена у автомобилей с признаком *NotRepaired* = *yes* и *NotRepaired* = *nan* равна.\n",
    "\n",
    "**H₁:** Средняя цена у автомобилей с признаком *NotRepaired* = *yes* и *NotRepaired* = *nan* различается."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средняя цена отремонтированного автомобиля 1916.0390802684863\n",
      "Средняя ценам автомобиля, данные по ремонту которого неизвестны: 2626.4192455800094\n"
     ]
    }
   ],
   "source": [
    "# <Посчитаем среднее для обоих выборок>\n",
    "yes_mean = df_preprocessed[df_preprocessed['NotRepaired'] == 'yes']['Price'].mean()\n",
    "nan_mean = df_preprocessed[(df_preprocessed['NotRepaired'] != 'no') & (df_preprocessed['NotRepaired'] != 'yes')]['Price'].mean()\n",
    "print('Средняя цена отремонтированного автомобиля', yes_mean)\n",
    "print('Средняя ценам автомобиля, данные по ремонту которого неизвестны:', nan_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <Создадим переменные для наших выборок>\n",
    "yes_data = df_preprocessed[df_preprocessed['NotRepaired'] == 'yes']['Price']\n",
    "nan_data = df_preprocessed[(df_preprocessed['NotRepaired'] != 'no') & (df_preprocessed['NotRepaired'] != 'yes')]['Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <импорт библиотеки scipy>\n",
    "from scipy import stats as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-значение: 6.76283705089867e-266\n",
      "Отвергаем нулевую гипотезу\n"
     ]
    }
   ],
   "source": [
    "# <Уровень значимости>\n",
    "alpha = 0.05\n",
    "\n",
    "# <Метод библиотеки scipy, позволяющий проверить гипотезу о равенстве двух средних>\n",
    "results =  st.ttest_ind(\n",
    "    yes_data, \n",
    "    nan_data)\n",
    "\n",
    "print('p-значение:', results.pvalue)\n",
    "\n",
    "if (results.pvalue < alpha):\n",
    "    print(\"Отвергаем нулевую гипотезу\")\n",
    "else:\n",
    "    print(\"Не получилось отвергнуть нулевую гипотезу\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Такая же ситуация ждет нас и с категорией *no*. Поэтому предлагаю заменить все *nan* значения на третью категорию *unknown*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessed['NotRepaired'] = (np.where(((df_preprocessed['NotRepaired'] != 'no') & (df_preprocessed['NotRepaired'] != 'yes')), \n",
    "                               'unknown', \n",
    "                               df_preprocessed.NotRepaired))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим столбец *RegistrationYear*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    354369.000000\n",
       "mean       2004.234448\n",
       "std          90.227958\n",
       "min        1000.000000\n",
       "25%        1999.000000\n",
       "50%        2003.000000\n",
       "75%        2008.000000\n",
       "max        9999.000000\n",
       "Name: RegistrationYear, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preprocessed['RegistrationYear'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На сайте *auto.ru* наиболее старый год для поиска объявления - 1890. Сделаем тут также, заменим все аномалии модой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessed['RegistrationYear'] = (np.where(((df_preprocessed['RegistrationYear'] < 1890) | (df_preprocessed['RegistrationYear'] > 2020)), \n",
    "                               df_preprocessed['RegistrationYear'].mode(), \n",
    "                               df_preprocessed.RegistrationYear))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим столбец *Kilometer*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    354369.000000\n",
       "mean     128211.172535\n",
       "std       37905.341530\n",
       "min        5000.000000\n",
       "25%      125000.000000\n",
       "50%      150000.000000\n",
       "75%      150000.000000\n",
       "max      150000.000000\n",
       "Name: Kilometer, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preprocessed['Kilometer'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В нем все довольно адекватно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим столбец *RegistrationMonth*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     37352\n",
       "3     34373\n",
       "6     31508\n",
       "4     29270\n",
       "5     29153\n",
       "7     27213\n",
       "10    26099\n",
       "12    24289\n",
       "11    24186\n",
       "9     23813\n",
       "1     23219\n",
       "8     22627\n",
       "2     21267\n",
       "Name: RegistrationMonth, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preprocessed['RegistrationMonth'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тут у нас 13 месяцев, но мы можем условиться, что 0 месяц - неизвестный, незаполненный. В условии задачи все равно не было сказано с какого числа считаются месяцы. Также заметим что скорее всего этот показатель будет иметь маленький вес."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим столбец *NumberOfPictures*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    354369\n",
       "Name: NumberOfPictures, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preprocessed['NumberOfPictures'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удалим этот столбец, он никак не будет влиять на обучение, если данные по нему у каждой строки одинаковые. Скорее всего такие значения результат ошибки загрзуки данных или хранения данных. Также удалим столбец *PostalCode*, почтовый индекс клиента анкеты никак не влияет на цену автомобиля."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <сбросим столбец>\n",
    "df_preprocessed = df_preprocessed.drop(['NumberOfPictures','PostalCode'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим количество дубликатов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30187"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# <проверим количество полных дубликатов>\n",
    "df_preprocessed.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08518521653982149"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preprocessed.duplicated().sum()/354369"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это плата за мой способ заполнения пропусков. Мы потеряем около 6 % данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <Сбросим дубликаты>\n",
    "df_preprocessed = df_preprocessed.drop_duplicates().reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы осмотрели данные и обработали пропуски. Данные практически подготовлены к обучению."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Обучение моделей <a class=\"anchor\" id=\"2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Переведем тип данных категориальных столбцов в *category*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessed['VehicleType'] = df_preprocessed['VehicleType'].astype('category')\n",
    "df_preprocessed['Gearbox'] = df_preprocessed['Gearbox'].astype('category')\n",
    "df_preprocessed['Model'] = df_preprocessed['Model'].astype('category')\n",
    "df_preprocessed['FuelType'] = df_preprocessed['FuelType'].astype('category')\n",
    "df_preprocessed['Brand'] = df_preprocessed['Brand'].astype('category')\n",
    "df_preprocessed['NotRepaired'] = df_preprocessed['NotRepaired'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим датафрейм на признаки и целевой признак."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <Разделим датафрейм на features и target - целевой признак>\n",
    "target = df_preprocessed['Price']\n",
    "features = df_preprocessed.drop('Price', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поделим датафрейм на обучающую и тестовую выборку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <Импортируем функцию из бибилиотеки sklearn>\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведем масштабирование признаков:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <импортируем StandardScaler из библиотеки sklearn>\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric = ['RegistrationYear','Power','Kilometer','RegistrationMonth']\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(features_train[numeric])\n",
    "features_train[numeric] = scaler.transform(features_train[numeric])\n",
    "features_test[numeric] = scaler.transform(features_test[numeric])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем библиотеку *LightGBM*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем использовать эту библиотеку, начнем с дерева принятия решений с градиентным бустингом (*gbdt: traditional Gradient Boosting Decision Tree*).\n",
    "\n",
    "Загружаем датасет в переменную, создаем словарь с параметрами:\n",
    "* *boosting_type* - алгоритм градиентного бустинга. Именно тут мы выбрали дерево принятия решений с градиентным бустингом.\n",
    "* *objective* - тут указывается регрессия это, либо классфикация.\n",
    "* *metric* - метрика по которой будем оценивать качество модели.\n",
    "* *learning_rate* - скорость обучения, при ее уменьшении можно получить более лучшие результаты.\n",
    "* *num_iterations* - количество итераций обучения.\n",
    "* *max_depth* - максимальная глубина дерева.\n",
    "* *num_leaves*  - количество листьев дерева."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Время выполнения ячейки - 6 минут 8 секунд."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\ttraining's rmse: 3653.96\n",
      "[200]\ttraining's rmse: 3051.97\n",
      "[300]\ttraining's rmse: 2636.81\n",
      "[400]\ttraining's rmse: 2354.12\n",
      "[500]\ttraining's rmse: 2159.79\n",
      "[600]\ttraining's rmse: 2027.77\n",
      "[700]\ttraining's rmse: 1938.29\n",
      "[800]\ttraining's rmse: 1876.4\n",
      "[900]\ttraining's rmse: 1832.99\n",
      "[1000]\ttraining's rmse: 1801.43\n",
      "[1100]\ttraining's rmse: 1776.75\n",
      "[1200]\ttraining's rmse: 1758.26\n",
      "[1300]\ttraining's rmse: 1743.31\n",
      "[1400]\ttraining's rmse: 1731.19\n",
      "[1500]\ttraining's rmse: 1721.28\n",
      "[1600]\ttraining's rmse: 1712.55\n",
      "[1700]\ttraining's rmse: 1704.73\n",
      "[1800]\ttraining's rmse: 1697.69\n",
      "[1900]\ttraining's rmse: 1691.13\n",
      "[2000]\ttraining's rmse: 1685.29\n",
      "[2100]\ttraining's rmse: 1679.55\n",
      "[2200]\ttraining's rmse: 1674.01\n",
      "[2300]\ttraining's rmse: 1669.34\n",
      "[2400]\ttraining's rmse: 1664.91\n",
      "[2500]\ttraining's rmse: 1660.67\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2500]\ttraining's rmse: 1660.67\n",
      "CPU times: user 6min 5s, sys: 2.36 s, total: 6min 8s\n",
      "Wall time: 6min 12s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "              importance_type='split', learning_rate=0.003, max_depth=10,\n",
       "              metric='rmse', min_child_samples=20, min_child_weight=0.001,\n",
       "              min_split_gain=0.0, n_estimators=100, n_jobs=-1,\n",
       "              num_iterations=2500, num_leaves=100, objective='regression',\n",
       "              random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "              subsample=1.0, subsample_for_bin=200000, subsample_freq=0,\n",
       "              task='train')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "hyper_params = {\n",
    "    'learning_rate': 0.003,\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    \"num_iterations\": 2500,\n",
    "    'max_depth': 10,\n",
    "    'num_leaves': 100\n",
    "}\n",
    "gbdt = lgb.LGBMRegressor(**hyper_params)\n",
    "gbdt.fit(features_train, target_train,\n",
    "        eval_set=[(features_train, target_train)],\n",
    "        eval_metric='rmse',\n",
    "        early_stopping_rounds=10, verbose = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь попробуем случайный лес. С ним обязательно нужно заполнить параметры *feature_fraction*, *bagging_fraction*, *bagging_freq*. Также увеличил количество листьев и кол-во деревьев."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Время выполнения ячейки - 5 минут 22 секунды."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds\n",
      "[250]\ttraining's rmse: 2202.31\n",
      "[500]\ttraining's rmse: 2226.43\n",
      "[750]\ttraining's rmse: 2221.67\n",
      "[1000]\ttraining's rmse: 2220.54\n",
      "[1250]\ttraining's rmse: 2227.99\n",
      "[1500]\ttraining's rmse: 2231.32\n",
      "[1750]\ttraining's rmse: 2235.11\n",
      "[2000]\ttraining's rmse: 2233.7\n",
      "[2250]\ttraining's rmse: 2231.96\n",
      "[2500]\ttraining's rmse: 2232.83\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[41]\ttraining's rmse: 2103.92\n",
      "CPU times: user 5min 20s, sys: 2.35 s, total: 5min 22s\n",
      "Wall time: 5min 24s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(bagging_fraction=0.3, bagging_freq=10, boosting_type='rf',\n",
       "              class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,\n",
       "              importance_type='split', learning_rate=0.1, max_depth=8,\n",
       "              metric='rmse', min_child_samples=20, min_child_weight=0.001,\n",
       "              min_split_gain=0.0, n_estimators=200, n_jobs=-1,\n",
       "              num_iterations=2500, num_leaves=300, objective='regression',\n",
       "              random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "              subsample=1.0, subsample_for_bin=200000, subsample_freq=0,\n",
       "              task='train')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "hyper_params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'rf',\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    \"num_iterations\": 2500,\n",
    "    'feature_fraction': 0.5,\n",
    "    'bagging_fraction': 0.3,\n",
    "    'bagging_freq': 10,\n",
    "    'num_leaves': 300,\n",
    "    'max_depth': 8,\n",
    "    'n_estimators': 200\n",
    "    \n",
    "}\n",
    "rf = lgb.LGBMRegressor(**hyper_params)\n",
    "rf.fit(features_train, target_train,\n",
    "        eval_set=[(features_train, target_train)],\n",
    "        eval_metric='rmse',\n",
    "        early_stopping_rounds=10, verbose = 250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь попробуем *Dropouts meet Multiple Additive Regression Trees*. Мною были изменены параметры скорости обучения и значения, которое определяет какое количество признаков использовать. Это необходимо чтобы обучение прошло быстрее, так как эта модель обучается медленно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Время выполнения ячейки - 7 минут 28 секунд."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\ttraining's rmse: 1777.73\n",
      "[100]\ttraining's rmse: 1706.85\n",
      "[150]\ttraining's rmse: 1663.86\n",
      "[200]\ttraining's rmse: 1633.84\n",
      "[250]\ttraining's rmse: 1616.81\n",
      "[300]\ttraining's rmse: 1598.64\n",
      "[350]\ttraining's rmse: 1589.55\n",
      "[400]\ttraining's rmse: 1572.88\n",
      "[450]\ttraining's rmse: 1557.22\n",
      "[500]\ttraining's rmse: 1543.29\n",
      "[550]\ttraining's rmse: 1532.05\n",
      "[600]\ttraining's rmse: 1530.61\n",
      "CPU times: user 7min 28s, sys: 667 ms, total: 7min 28s\n",
      "Wall time: 7min 32s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(boosting_type='dart', class_weight=None, colsample_bytree=1.0,\n",
       "              feature_fraction=0.5, importance_type='split', learning_rate=0.7,\n",
       "              max_depth=-1, metric='rmse', min_child_samples=20,\n",
       "              min_child_weight=0.001, min_split_gain=0.0, n_estimators=100,\n",
       "              n_jobs=-1, num_iterations=600, num_leaves=31,\n",
       "              objective='regression', random_state=None, reg_alpha=0.0,\n",
       "              reg_lambda=0.0, silent=True, subsample=1.0,\n",
       "              subsample_for_bin=200000, subsample_freq=0, task='train')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "hyper_params = {\n",
    "    'learning_rate': 0.7,\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'dart',\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    \"num_iterations\": 600,\n",
    "    'feature_fraction': 0.5\n",
    "}\n",
    "dart_model = lgb.LGBMRegressor(**hyper_params)\n",
    "dart_model.fit(features_train, target_train,\n",
    "        eval_set=[(features_train, target_train)],\n",
    "        eval_metric='rmse',\n",
    "        early_stopping_rounds=10, verbose = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем обучить обыкновенную линейную регрессию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <Преобразуем категориальные признаки в фиктивные переменные, и сбросим по одному из них у каждого признака.>\n",
    "features_train_1 = pd.get_dummies(features_train, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <Импортируем метод логистической регрессии>\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# <Импортируем функцию cross_val_score>\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Время выполнения ячейки - 1 минута 50 секунд."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 27s, sys: 23 s, total: 1min 50s\n",
      "Wall time: 1min 50s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# <Создадим модель лог. регрессии,>\n",
    "model_lr = LinearRegression()\n",
    "\n",
    "# <Оценим качество модели, обученной в ходе перекрестной проверки>\n",
    "score = cross_val_score(model_lr, features_train_1, target_train, cv=4, scoring='neg_mean_squared_error').mean()\n",
    "\n",
    "# <обучаем модель> \n",
    "model_lr.fit(features_train_1, target_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы обучили несколько моделей с градиентным бустингом, а также линейную регрессию. В следующем пункте проанализируем их скорость работы и качество."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Анализ моделей <a class=\"anchor\" id=\"3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим на тестовой выборке дерево принятия решений с градиентным бустингом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1747.736487415676"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = gbdt.predict(features_test)\n",
    "mean_squared_error(target_test,predictions)**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим на тестовой выборке случайный лес с градиентным бустингом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2114.207575737013"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = rf.predict(features_test)\n",
    "mean_squared_error(target_test,predictions)**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим на тестовой выборке *Dropouts meet Multiple Additive Regression Trees(DART)*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1726.9859952149693"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = dart_model.predict(features_test)\n",
    "mean_squared_error(target_test,predictions)**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим на тестовой выборке линейную регрессию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <Преобразуем категориальные признаки в фиктивные переменные, и сбросим по одному из них у каждого признака.>\n",
    "features_test_1 = pd.get_dummies(features_test, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3036.405060534749"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model_lr.predict(features_test_1)\n",
    "mean_squared_error(target_test,predictions)**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подытожим результаты:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>rmse</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Линейная регрессия</td>\n",
       "      <td>3036.40</td>\n",
       "      <td>1:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>1747.74</td>\n",
       "      <td>6:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>rf</td>\n",
       "      <td>2114.20</td>\n",
       "      <td>5:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>dart</td>\n",
       "      <td>1726.99</td>\n",
       "      <td>7:28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                model     rmse  time\n",
       "0  Линейная регрессия  3036.40  1:50\n",
       "1                gbdt  1747.74  6:08\n",
       "2                  rf  2114.20  5:22\n",
       "3                dart  1726.99  7:28"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = {'model': ['Линейная регрессия', 'gbdt','rf','dart'], \n",
    "           'rmse': [3036.4, 1747.74, 2114.2, 1726.99],\n",
    "           'time': ['1:50','6:08','5:22','7:28']\n",
    "          }\n",
    "results = pd.DataFrame(data=results)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Наиболее быстрой в плане обучения является модель линейной регресии. Однако если выставить определенное количество итераций три других метода за то же время что и линейная регрессия дадут лучший результат.\n",
    "* Среди моделей с градиентным бустингом наиболее быстро обучилась модель случайного леса, но при этом на большинстве итераций не происходило положительной динамики улучшения *RMSE*\n",
    "* Самой медленной моделью, но при этом выдающей самый качественный результат является модель *DART*, при определенных параметрах и большом количестве итераций можно было получить *RMSE* < 1000.\n",
    "* Стабильной и в плане скорости, и в плане улучшения *RMSE* показала себя модель *gbdt*."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
