{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Отток клиентов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Необходимо спрогнозировать, уйдёт клиент из банка в ближайшее время или нет. Предоставлены исторические данные о поведении клиентов и расторжении договоров с банком.\n",
    "\n",
    "Источник данных: [https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling](https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оглавление:\n",
    "* [1. Подготовка данных](#1)\n",
    "* [2. Исследование задачи](#2)\n",
    "* [3. Борьба с дисбалансом](#3)\n",
    "* [4. Тестирование модели](#4)\n",
    "* [Чек-лист готовности проекта](#5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Подготовка данных <a class=\"anchor\" id=\"1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем библиотеки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <импорт библиотеки pandas>\n",
    "import pandas as pd\n",
    "\n",
    "# <импорт библиотеки math>\n",
    "import math\n",
    "\n",
    "# <импорт библиотеки sklearn>\n",
    "import sklearn\n",
    "\n",
    "# <Отключение предупреждений>\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# <импорт библиотеки numpy>\n",
    "import numpy as np\n",
    "\n",
    "# <импорт библиотеки seaborn для построения графиков>\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прочитаем файл с данными:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <чтение файла с данными с сохранением в переменную df>\n",
    "df = pd.read_csv('/datasets/Churn.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим информацию по датафрейму и первые 5 строк:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      "RowNumber          10000 non-null int64\n",
      "CustomerId         10000 non-null int64\n",
      "Surname            10000 non-null object\n",
      "CreditScore        10000 non-null int64\n",
      "Geography          10000 non-null object\n",
      "Gender             10000 non-null object\n",
      "Age                10000 non-null int64\n",
      "Tenure             9091 non-null float64\n",
      "Balance            10000 non-null float64\n",
      "NumOfProducts      10000 non-null int64\n",
      "HasCrCard          10000 non-null int64\n",
      "IsActiveMember     10000 non-null int64\n",
      "EstimatedSalary    10000 non-null float64\n",
      "Exited             10000 non-null int64\n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0     2.0       0.00              1          1               1   \n",
       "1     1.0   83807.86              1          0               1   \n",
       "2     8.0  159660.80              3          1               0   \n",
       "3     1.0       0.00              2          0               0   \n",
       "4     2.0  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# <рассмотрим датафрейм df>\n",
    "print(df.info())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Имеются пропуски в признаке *Tenure* — количество недвижимости у клиента. Если в количестве недвижимости пропуски, самым разумным предположением выглядит тот факт что недвижимости у клиента нет (живет у родственников или снимает квартиру, например)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <Заменим значения количества недвижимости равные NaN на 0> \n",
    "df['Tenure'] = (\n",
    "np.where((np.isnan(df.Tenure)), 0, df.Tenure)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сменим тип данных на целочисленный в этом столбце, мне кажется в реальных задачах это было бы кстати, например для экономии памяти."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <поменяем тип на целочисленный>\n",
    "df['Tenure'] = df['Tenure'].astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим новый датафрейм, удалим из него столбцы *Surname* и *RowNumber*, которые не влияют на столбец *Exited*. \n",
    "* Клиенты в датафрейме расположены не по порядку возрастания *CustomerId*, который может в теории указывать нам на то, насколько давно клиент сотрудничает с банком, соответственно номер строки никак не влияет на наш целевой признак. \n",
    "* Различных фамилий в датафрейме более двух тысяч, соответственно использовав их мы только усложним модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <сбросим два столбца, которые не помогу нам предсказать целевой признак>\n",
    "df_ohe = df.drop(['Surname','RowNumber'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразуем категориальные признаки в количественные с помощью техники прямого кодирования (**OHE**), в этом поможет метод *.get_dummies*. Также проставим аргумент *drop_first = True*, чтобы один из столбцов наших фиктивных переменных для каждого признака был сброшен(это нужно чтобы не угодить в так называемую *дамми-ловушку*, когда фиктивных признаков слишком много). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <Преобразуем категориальные признаки в фиктивные переменные, и сбросим по одному из них у каждого признака.>\n",
    "df_ohe = pd.get_dummies(df_ohe, drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Взглянем на датафрейм:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 13 columns):\n",
      "CustomerId           10000 non-null int64\n",
      "CreditScore          10000 non-null int64\n",
      "Age                  10000 non-null int64\n",
      "Tenure               10000 non-null int64\n",
      "Balance              10000 non-null float64\n",
      "NumOfProducts        10000 non-null int64\n",
      "HasCrCard            10000 non-null int64\n",
      "IsActiveMember       10000 non-null int64\n",
      "EstimatedSalary      10000 non-null float64\n",
      "Exited               10000 non-null int64\n",
      "Geography_Germany    10000 non-null uint8\n",
      "Geography_Spain      10000 non-null uint8\n",
      "Gender_Male          10000 non-null uint8\n",
      "dtypes: float64(2), int64(8), uint8(3)\n",
      "memory usage: 810.7 KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>15634602</td>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>15647311</td>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>15619304</td>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>15701354</td>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>15737888</td>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CustomerId  CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0    15634602          619   42       2       0.00              1          1   \n",
       "1    15647311          608   41       1   83807.86              1          0   \n",
       "2    15619304          502   42       8  159660.80              3          1   \n",
       "3    15701354          699   39       1       0.00              2          0   \n",
       "4    15737888          850   43       2  125510.82              1          1   \n",
       "\n",
       "   IsActiveMember  EstimatedSalary  Exited  Geography_Germany  \\\n",
       "0               1        101348.88       1                  0   \n",
       "1               1        112542.58       0                  0   \n",
       "2               0        113931.57       1                  0   \n",
       "3               0         93826.63       0                  0   \n",
       "4               1         79084.10       0                  0   \n",
       "\n",
       "   Geography_Spain  Gender_Male  \n",
       "0                0            0  \n",
       "1                1            0  \n",
       "2                0            0  \n",
       "3                0            0  \n",
       "4                1            0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# <Посмотрим первые 5 строк преобразованного датафрейма>\n",
    "print(df_ohe.info())\n",
    "df_ohe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разобьем данные на две выборки: обучающую + валидационную и тестовую. Разобьем их в отношении 4:1, попробуем использовать в этом проекте кросс-валидацию, проставив относящийся к ней аргумент в методе *GridSearchCV*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <Импортируем функцию из бибилиотеки sklearn>\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <Разделим обучающий датафрейм на features и target - целевой признак>\n",
    "target = df_ohe['Exited']\n",
    "features = df_ohe.drop('Exited', axis=1)\n",
    "\n",
    "# <Поделим датафрейм на обучающую выборку + валидационную выборку (которая далее будет использована для кросс-валидации) и тестовую выборку.>\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features, target, test_size=0.2, random_state=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведем масштабирование признаков:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <импортируем StandardScaler из библиотеки sklearn>\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <конкретизируем какие признаки будем масшатбировать>\n",
    "numeric = ['CustomerId', 'CreditScore', 'Age', 'Tenure','Balance', 'NumOfProducts', 'EstimatedSalary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <Проведем масштабирование features_train>\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(features_train[numeric])\n",
    "features_train[numeric] = scaler.transform(features_train[numeric])\n",
    "features_test[numeric] = scaler.transform(features_test[numeric])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Мы осмотрели данные и заполнили пропуски самым очевидным образом.\n",
    "* Мы сменили тип данных, так как количество недвижимости дробится не может, и целочисленный тип здесь подходит лучше\n",
    "* Мы удалили из датафрейма столбцы, которые никак не помогут вычислить целевой признак.\n",
    "* Преобразовали категориальные признаки в количественные с помощью техники прямого кодирования (OHE), создали для этих признаков количественные фиктивные переменные.\n",
    "* Провели масштабирование признаков, чтобы алгоритм обучения не делал выводов о том что тот или иной признак важнее только из-за того что он измеряется в больших числах.\n",
    "* Разделили данные на обучающую + валидационную и тестовую выборки. Первую будем использовать для обучения и валидации когда будем перебирать гиперпараметры с помощью *GridSearchCV* - метода для исчерпывающего поиска по сетке гиперпараметров."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Исследование задачи <a class=\"anchor\" id=\"2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Исследуем баланс классов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.7963\n",
      "1    0.2037\n",
      "Name: Exited, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f677b9a87d0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_frequency = target.value_counts(normalize=True)\n",
    "print(class_frequency)\n",
    "class_frequency.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "80% клиентов в датафрейме из банка не уходят - в классах дисбаланс. Идеальным балансом чтобы строить модели можно было бы назвать распределение 50/50. Попробуем обучить модель, несмотря на дисбаланс."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем использовать *GridSearchCV* для подбора параметров модели дерева принятия решений. Я слышал что использование таких методов не рекомендуется в проекте без понимания того что в них происходит, поэтому постараюсь разъяснить код:\n",
    "\n",
    "* *param_grid* это словарь в котором указываются гиперпараметры и интервалы в которых они могут находится, или в случае если это категориальные признаки - возможные значения.\n",
    "* в *np.arange* в качестве третьего аргумента шаг. Первый и второй аргумент - начало и конец последовательности. np.arange(0.5, 1, 0.1) - тут в последовательности не будет единицы но будет [0.5, 0.6, 0.7, 0.8, 0.9].\n",
    "* *max_leaf_nodes* - максимальное количество листовых узлов (нижние узлы с ответами).\n",
    "* *max_features* - количеcтво используемых признаков.\n",
    "* *min_samples_split* - минимальное число объектов, при котором выполняется расщепление на узлы.\n",
    "* аргумент *cv* необходим для кросс-валидации, я изучил следующий спринт после этого, и поэтому имею представление о ней. Я выбрал 4 блока, так как ранее нам рекомедовали делить выборку на обучающую, валидационную и тестовую в соотношении 3:1:1. Соответственно 4 фолда это три фолда для обучения и один для валидации.\n",
    "* аргумент *scoring* указывает как будем оценивать модели, для моделей классификации необходимо использовать F1-меру."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 21s, sys: 156 ms, total: 1min 21s\n",
      "Wall time: 1min 21s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, error_score='raise-deprecating',\n",
       "             estimator=DecisionTreeClassifier(class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features=None,\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              presort=False, random_state=12345,\n",
       "                                              splitter='best'),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'max_depth': [None, 2, 4, 6, 8, 10, 12, 14, 16, 18,\n",
       "                                       20],\n",
       "                         'max_features': ['auto', 'sqrt', None],\n",
       "                         'max_leaf_nodes': [None, 10, 20, 30, 40, 50, 60, 70,\n",
       "                                            80, 90, 100],\n",
       "                         'min_samples_split': [2, 5, 10]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='f1', verbose=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# <импортируем алгоритм исчерпывающего поиска по гиперпараметрам>\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# <Импортируем метод дерева принятия решений>\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "# <сетка гиперпараметров, по которой будет происходит исчерпывающий поиск>\n",
    "param_grid = {\n",
    "    'max_depth': [None] + list(np.arange(2, 21,2).astype(int)),\n",
    "    'max_features': ['auto', 'sqrt', None],\n",
    "    'max_leaf_nodes': [None] + list(np.arange(10, 101, 10).astype(int)),\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# <дерево принятия решений к которому будем подбирать параметры>\n",
    "estimator = DecisionTreeClassifier(random_state = 12345)\n",
    "\n",
    "# <модель>\n",
    "model = GridSearchCV(estimator, param_grid, cv=4, scoring = 'f1')\n",
    "\n",
    "# <обучаем модель> \n",
    "model.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5778748424367518"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# <среднее значение F1-меры по разным выборкам>\n",
    "model.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценка неплоха, близка к оценке, к которой мы стремимся."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы посчитать для этой модели *AUC-ROC*, пришлось поднапрячься. В данном блоке мы импортируем саму оценку, скидываем индексы выборкам, так как если этого не сделать, в некоторых строках будет *NaN*. Далее мы выбираем количество наших блоков кросс-валидации = 4. И затем подсчитываем *AUC_ROC* для каждого варианта обучающей и валидационной выборки. Затем подсчитываем их среднее и получаем финальную оценку:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8716567180657411"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "features_train = features_train.reset_index(drop = True)\n",
    "target_train = target_train.reset_index(drop = True)\n",
    "\n",
    "auc_roc_scores = []\n",
    "\n",
    "sample_size = int(len(features_train)/4)\n",
    "\n",
    "for i in range(0, len(features_train), sample_size):\n",
    "    valid_indexes = list(range(i, i + sample_size))\n",
    "    train_indexes = list(range(0,len(features_train)))\n",
    "    del train_indexes[i:(i + sample_size)]\n",
    "    \n",
    "    features_valid = features_train.loc[valid_indexes,]\n",
    "    target_valid = target_train.loc[valid_indexes,]\n",
    "    probabilities_valid = model.predict_proba(features_valid)\n",
    "    probabilities_one_valid = probabilities_valid[:, 1]\n",
    "    auc_roc = roc_auc_score(target_valid,probabilities_one_valid)\n",
    "        \n",
    "    auc_roc_scores.append(auc_roc)\n",
    "\n",
    "auc_roc_scores = pd.Series(auc_roc_scores)\n",
    "final_score = auc_roc_scores.mean()\n",
    "final_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эта оценка выше 0.5, а значит проходит проверку на адекватность. Но нам относительно далеко до идеальной оценки = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 10,\n",
       " 'max_features': None,\n",
       " 'max_leaf_nodes': 60,\n",
       " 'min_samples_split': 2}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# <набор параметров, которые подобрал исчерпывающий поиск по гиперпараметрам модели.>\n",
    "model.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем *RandomizedSearchCV* - случайный поиск по гиперпараметрам с моделью случайного леса.\n",
    "* *bootstrap* - Бутстрэп-агрегирование или бэггинг, алгоритм предназначенный для улучшения стабильности и точности алгоритмов машинного обучения, также уменьшает дисперсию и помогает избежать переобучения. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.8 s, sys: 36 ms, total: 13.8 s\n",
      "Wall time: 13.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=4, error_score='raise-deprecating',\n",
       "                   estimator=RandomForestClassifier(bootstrap=True,\n",
       "                                                    class_weight=None,\n",
       "                                                    criterion='gini',\n",
       "                                                    max_depth=None,\n",
       "                                                    max_features='auto',\n",
       "                                                    max_leaf_nodes=None,\n",
       "                                                    min_impurity_decrease=0.0,\n",
       "                                                    min_impurity_split=None,\n",
       "                                                    min_samples_leaf=1,\n",
       "                                                    min_samples_split=2,\n",
       "                                                    min_weight_fraction_leaf=0.0,\n",
       "                                                    n_estimators='warn',\n",
       "                                                    n_jobs=None,\n",
       "                                                    oob_sc...\n",
       "                                        'max_depth': [None, 2, 4, 6, 8, 10, 12,\n",
       "                                                      14, 16, 18, 20],\n",
       "                                        'max_features': ['auto', 'sqrt', None],\n",
       "                                        'max_leaf_nodes': [None, 10, 20, 30, 40,\n",
       "                                                           50, 60, 70, 80, 90,\n",
       "                                                           100],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [2, 4, 6, 8, 10, 12, 14,\n",
       "                                                         16, 18, 20, 22, 24, 26,\n",
       "                                                         28, 30, 32, 34, 36, 38,\n",
       "                                                         40, 42, 44, 46, 48, 50,\n",
       "                                                         52, 54, 56, 58, 60, ...]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring='f1', verbose=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# <Импортируем алгоритм случайного леса>\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# <Импортируем алгоритм случайного поиска по гиперпараметрам>\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "\n",
    "# <сетка гиперпараметров, по которой будет происходит случайный поиск>\n",
    "param_grid = {\n",
    "    'n_estimators': list(np.arange(2, 101, 2).astype(int)),\n",
    "    'max_depth': [None] + list(np.arange(2, 21,2).astype(int)),\n",
    "    'max_features': ['auto', 'sqrt', None],\n",
    "    'max_leaf_nodes': [None] + list(np.arange(10, 101, 10).astype(int)),\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# <случайный лес к которому будем подбирать параметры>\n",
    "estimator = RandomForestClassifier(random_state = 12345)\n",
    "\n",
    "# <модель>\n",
    "model_rf = RandomizedSearchCV(estimator, param_grid, cv=4, scoring = 'f1')\n",
    "\n",
    "# <обучаем модель> \n",
    "model_rf.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5788257377531885"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# <среднее значение F1-меры по разным выборкам>\n",
    "model_rf.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценка хуже чем у одного дерева принятия решений. Подсчитаем *AUC-ROC*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9035105997475861"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "auc_roc_scores = []\n",
    "\n",
    "sample_size = int(len(features_train)/4)\n",
    "\n",
    "for i in range(0, len(features_train), sample_size):\n",
    "    valid_indexes = list(range(i, i + sample_size))\n",
    "    train_indexes = list(range(0,len(features_train)))\n",
    "    del train_indexes[i:(i + sample_size)]\n",
    "    \n",
    "    features_valid = features_train.loc[valid_indexes,]\n",
    "    target_valid = target_train.loc[valid_indexes,]\n",
    "    probabilities_valid = model_rf.predict_proba(features_valid)\n",
    "    probabilities_one_valid = probabilities_valid[:, 1]\n",
    "    auc_roc = roc_auc_score(target_valid,probabilities_one_valid)    \n",
    "    \n",
    "    auc_roc_scores.append(auc_roc)\n",
    "\n",
    "auc_roc_scores = pd.Series(auc_roc_scores)\n",
    "final_score = auc_roc_scores.mean()\n",
    "final_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценка разнится в зависимости от отработки случайного поиска, но примерно равна таковой у дерева принятия решений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 8,\n",
       " 'min_samples_split': 10,\n",
       " 'max_leaf_nodes': 100,\n",
       " 'max_features': None,\n",
       " 'max_depth': None,\n",
       " 'bootstrap': True}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# <набор параметров, которые подобрал исчерпывающий поиск по гиперпараметрам модели.>\n",
    "model_rf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем логистическую регрессию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <Импортируем метод логистической регрессии>\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# <Импортируем функцию cross_val_score>\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32185993064665314"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# <Создадим модель лог. регрессии,>\n",
    "model_lr = LogisticRegression(random_state=12345)\n",
    "\n",
    "# <Оценим качество модели, обученной в ходе перекрестной проверки>\n",
    "score = cross_val_score(model_lr,features_train, target_train,cv=4,scoring='f1').mean()\n",
    "\n",
    "# <обучаем модель> \n",
    "model_lr.fit(features_train, target_train)\n",
    "\n",
    "# <выведем долю правильных ответов>\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Слабая оценка. В следующем пункте попробуем избавиться от дисбаланса, и снова обучить модель. Подсчитаем *AUC-ROC*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7684252256491437"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "auc_roc_scores = []\n",
    "\n",
    "sample_size = int(len(features_train)/4)\n",
    "\n",
    "for i in range(0, len(features_train), sample_size):\n",
    "    valid_indexes = list(range(i, i + sample_size))\n",
    "    train_indexes = list(range(0,len(features_train)))\n",
    "    del train_indexes[i:(i + sample_size)]\n",
    "    \n",
    "    features_valid = features_train.loc[valid_indexes,]\n",
    "    target_valid = target_train.loc[valid_indexes,]\n",
    "    \n",
    "    probabilities_valid = model_lr.predict_proba(features_valid)\n",
    "    probabilities_one_valid = probabilities_valid[:, 1]\n",
    "    auc_roc = roc_auc_score(target_valid,probabilities_one_valid)\n",
    "        \n",
    "    auc_roc_scores.append(auc_roc)\n",
    "\n",
    "auc_roc_scores = pd.Series(auc_roc_scores)\n",
    "final_score = auc_roc_scores.mean()\n",
    "final_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самая низкая оценка."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Мы оценили сбалансированность целевого признака, и выяснили что в нем присутствует дисбаланс.\n",
    "* Подобрали лучшие гиперпараметры для дерева принятия решений с помощью метода *GridSearchCV*.\n",
    "* Подобрали гиперпараметры для случайного леса с помощью метода *RandomizedSearchCV*. Получили результат примерно равный результату у дерева принятия решений.\n",
    "* Попробовали обучить логистическую регрессию, но получили оценку гораздо хуже чем у \"деревянных\" алгоритмов.\n",
    "\n",
    "В следующем пункте избавимся от дисбаланса и снова обучим модель."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Борьба с дисбалансом <a class=\"anchor\" id=\"3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Начнем, относительно, с начала. Это необходимо, так как кросс-валидацию и перебор параметров теперь нам придется проводить самостоятельно. Пришлось делать именно так из-за того я не имею представления как делать *upsampling* в методах аля  *GridSearchCV*, единственное что там обнаружено для баланса классов - *class_weight = 'balanced'*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем оценку и функцию для *upsampling*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <импортируем оценку F1-меры>\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# <импортируем функцию resample>\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном цикле происходит перебор моделей дерева принятия решений с различными гиперпараметрами, затем идет оценка модели на валидационной выборке, используется кросс-валидация, написанная на питоне. Она была изучена в следующем спринте. Также происходит апсемплинг положительного класса.\n",
    "\n",
    "Здесь и далее будет происходит перебор не всех возможных значений гиперпараметров, я специально напишу код так, чтобы в переменной model была сохранена лучшая модель и можно было бы быстрее посчитать *AUC-ROC*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth = 2 min_samples_split = 2 : 0.5133\n",
      "max_depth = 2 min_samples_split = 5 : 0.5133\n",
      "max_depth = 2 min_samples_split = 10 : 0.5133\n",
      "max_depth = 4 min_samples_split = 2 : 0.5252\n",
      "max_depth = 4 min_samples_split = 5 : 0.5252\n",
      "max_depth = 4 min_samples_split = 10 : 0.5252\n",
      "max_depth = 6 min_samples_split = 2 : 0.5604\n",
      "max_depth = 6 min_samples_split = 5 : 0.5604\n",
      "max_depth = 6 min_samples_split = 10 : 0.5606\n",
      "CPU times: user 1.69 s, sys: 8 ms, total: 1.7 s\n",
      "Wall time: 1.72 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for depth in range(2,7,2):\n",
    "    for samples in [2, 5, 10]:\n",
    "        model = DecisionTreeClassifier(random_state=0, max_depth=depth, \n",
    "                                               min_samples_split = samples\n",
    "                                               )\n",
    "                \n",
    "        sample_size = int(len(features_train)/4)\n",
    "        scores = []\n",
    "        \n",
    "        for i in range(0, len(features_train), sample_size):\n",
    "            valid_indexes = list(range(i, i + sample_size))\n",
    "            train_indexes = list(range(0,len(features_train)))\n",
    "                    \n",
    "            del train_indexes[i:(i + sample_size)]\n",
    "                    \n",
    "            features_train_1 = features_train.loc[train_indexes,]\n",
    "            features_valid = features_train.loc[valid_indexes,]\n",
    "            target_train_1 = target_train.loc[train_indexes,]\n",
    "            target_valid = target_train.loc[valid_indexes,]\n",
    "                    \n",
    "            features_train_1['Exited'] = target_train_1\n",
    "                \n",
    "            features_train_majority = features_train_1[features_train_1.Exited==0]\n",
    "            features_train_minority = features_train_1[features_train_1.Exited==1]\n",
    "                    \n",
    "            features_train_minority_upsampled = resample(features_train_minority, \n",
    "                                 replace=True,     \n",
    "                                 n_samples=int(features_train_majority['Age'].count()),    \n",
    "                                 random_state=123)\n",
    "            \n",
    "            features_train_upsampled = pd.concat([features_train_majority, features_train_minority_upsampled])\n",
    "                    \n",
    "                    \n",
    "            target_train_upsampled = features_train_upsampled['Exited']\n",
    "            features_train_upsampled = features_train_upsampled.drop('Exited', axis=1)\n",
    "                    \n",
    "            model.fit(features_train_upsampled, target_train_upsampled)\n",
    "            predictions = model.predict(features_valid)\n",
    "            score = f1_score(target_valid, predictions)\n",
    "            scores.append(score)\n",
    "                    \n",
    "            if i == (sample_size * 3):\n",
    "                scores = pd.Series(scores)\n",
    "                print('max_depth =',depth,'min_samples_split =',samples,': {:.4f}'.format(scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучшая оценка у дерева с параметрами *max_depth* = 6, *min_samples_split* = 10. Она равна 0.5606. Она ниже чем у дерева, подобранного *GridSearchCV*. Но и гиперпараметров мы перебирали меньше. Подсчитаем *AUC-ROC*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8516201750440057"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "auc_roc_scores = []\n",
    "\n",
    "sample_size = int(len(features_train)/4)\n",
    "\n",
    "for i in range(0, len(features_train), sample_size):\n",
    "    valid_indexes = list(range(i, i + sample_size))\n",
    "    train_indexes = list(range(0,len(features_train)))\n",
    "    del train_indexes[i:(i + sample_size)]\n",
    "    \n",
    "    features_valid = features_train.loc[valid_indexes,]\n",
    "    target_valid = target_train.loc[valid_indexes,]\n",
    "    probabilities_valid = model.predict_proba(features_valid)\n",
    "    probabilities_one_valid = probabilities_valid[:, 1]\n",
    "    auc_roc = roc_auc_score(target_valid,probabilities_one_valid)    \n",
    "    \n",
    "    auc_roc_scores.append(auc_roc)\n",
    "\n",
    "auc_roc_scores = pd.Series(auc_roc_scores)\n",
    "final_score = auc_roc_scores.mean()\n",
    "final_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее опробуем тоже самое обучение на логистической регресии:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score = 0.4864\n",
      "CPU times: user 396 ms, sys: 288 ms, total: 684 ms\n",
      "Wall time: 671 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = LogisticRegression()\n",
    "                \n",
    "sample_size = int(len(features_train)/4)\n",
    "scores = []\n",
    "        \n",
    "for i in range(0, len(features_train), sample_size):\n",
    "    valid_indexes = list(range(i, i + sample_size))\n",
    "    train_indexes = list(range(0,len(features_train)))\n",
    "                    \n",
    "    del train_indexes[i:(i + sample_size)]\n",
    "                    \n",
    "    features_train_1 = features_train.loc[train_indexes,]\n",
    "    features_valid = features_train.loc[valid_indexes,]\n",
    "    target_train_1 = target_train.loc[train_indexes,]\n",
    "    target_valid = target_train.loc[valid_indexes,]\n",
    "                    \n",
    "    features_train_1['Exited'] = target_train_1\n",
    "                \n",
    "    features_train_majority = features_train_1[features_train_1.Exited==0]\n",
    "    features_train_minority = features_train_1[features_train_1.Exited==1]\n",
    "                    \n",
    "    features_train_minority_upsampled = resample(features_train_minority, \n",
    "                                 replace=True,     \n",
    "                                 n_samples=int(features_train_majority['Age'].count()),    \n",
    "                                 random_state=123)\n",
    "            \n",
    "    features_train_upsampled = pd.concat([features_train_majority, features_train_minority_upsampled])\n",
    "                    \n",
    "                    \n",
    "    target_train_upsampled = features_train_upsampled['Exited']\n",
    "    features_train_upsampled = features_train_upsampled.drop('Exited', axis=1)\n",
    "                    \n",
    "    model.fit(features_train_upsampled, target_train_upsampled)\n",
    "    predictions = model.predict(features_valid)\n",
    "    score = f1_score(target_valid, predictions)\n",
    "    scores.append(score)\n",
    "                    \n",
    "    if i == (sample_size * 3):\n",
    "        scores = pd.Series(scores)\n",
    "        print('f1_score =','{:.4f}'.format(scores.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7703709282341126"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "auc_roc_scores = []\n",
    "\n",
    "sample_size = int(len(features_train)/4)\n",
    "\n",
    "for i in range(0, len(features_train), sample_size):\n",
    "    valid_indexes = list(range(i, i + sample_size))\n",
    "    train_indexes = list(range(0,len(features_train)))\n",
    "    del train_indexes[i:(i + sample_size)]\n",
    "    \n",
    "    features_valid = features_train.loc[valid_indexes,]\n",
    "    target_valid = target_train.loc[valid_indexes,]\n",
    "    probabilities_valid = model.predict_proba(features_valid)\n",
    "    probabilities_one_valid = probabilities_valid[:, 1]\n",
    "    auc_roc = roc_auc_score(target_valid,probabilities_one_valid)    \n",
    "    \n",
    "    auc_roc_scores.append(auc_roc)\n",
    "\n",
    "auc_roc_scores = pd.Series(auc_roc_scores)\n",
    "final_score = auc_roc_scores.mean()\n",
    "final_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат улучшился и довольно сильно, баланс классов имеет большое значение для логистической регрессии."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем наш алгоритм перебора и обучения с апсемплингом на случайном лесе. Здесь установим гиперпараметры дерева те что подобрали у дерева принятия решений и будем перебирать только количество деревьев."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 2 : 0.5654\n",
      "n_estimators = 4 : 0.5734\n",
      "n_estimators = 6 : 0.5752\n",
      "n_estimators = 8 : 0.5801\n",
      "n_estimators = 10 : 0.5866\n",
      "n_estimators = 12 : 0.5907\n",
      "n_estimators = 14 : 0.5921\n",
      "n_estimators = 16 : 0.5958\n",
      "n_estimators = 18 : 0.5992\n",
      "CPU times: user 4.02 s, sys: 48 ms, total: 4.07 s\n",
      "Wall time: 4.14 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for estimators in range(2,20,2):\n",
    "    model = RandomForestClassifier(random_state=0, max_depth=6, \n",
    "                                               min_samples_split = 10,\n",
    "                                               n_estimators = estimators)\n",
    "                \n",
    "    sample_size = int(len(features_train)/4)\n",
    "    scores = []\n",
    "        \n",
    "    for i in range(0, len(features_train), sample_size):\n",
    "        valid_indexes = list(range(i, i + sample_size))\n",
    "        train_indexes = list(range(0,len(features_train)))\n",
    "                    \n",
    "        del train_indexes[i:(i + sample_size)]\n",
    "                    \n",
    "        features_train_1 = features_train.loc[train_indexes,]\n",
    "        features_valid = features_train.loc[valid_indexes,]\n",
    "        target_train_1 = target_train.loc[train_indexes,]\n",
    "        target_valid = target_train.loc[valid_indexes,]\n",
    "                    \n",
    "        features_train_1['Exited'] = target_train_1\n",
    "                \n",
    "        features_train_majority = features_train_1[features_train_1.Exited==0]\n",
    "        features_train_minority = features_train_1[features_train_1.Exited==1]\n",
    "                    \n",
    "        features_train_minority_upsampled = resample(features_train_minority, \n",
    "                                 replace=True,     \n",
    "                                 n_samples=int(features_train_majority['Age'].count()),    \n",
    "                                 random_state=123)\n",
    "            \n",
    "        features_train_upsampled = pd.concat([features_train_majority, features_train_minority_upsampled])\n",
    "                    \n",
    "                    \n",
    "        target_train_upsampled = features_train_upsampled['Exited']\n",
    "        features_train_upsampled = features_train_upsampled.drop('Exited', axis=1)\n",
    "                    \n",
    "        model.fit(features_train_upsampled, target_train_upsampled)\n",
    "        predictions = model.predict(features_valid)\n",
    "        score = f1_score(target_valid, predictions)\n",
    "        scores.append(score)\n",
    "                    \n",
    "        if i == (sample_size * 3):\n",
    "            scores = pd.Series(scores)\n",
    "            print('n_estimators =',estimators,': {:.4f}'.format(scores.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8792165685539199"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "auc_roc_scores = []\n",
    "\n",
    "sample_size = int(len(features_train)/4)\n",
    "\n",
    "for i in range(0, len(features_train), sample_size):\n",
    "    valid_indexes = list(range(i, i + sample_size))\n",
    "    train_indexes = list(range(0,len(features_train)))\n",
    "    del train_indexes[i:(i + sample_size)]\n",
    "    \n",
    "    features_valid = features_train.loc[valid_indexes,]\n",
    "    target_valid = target_train.loc[valid_indexes,]\n",
    "    probabilities_valid = model.predict_proba(features_valid)\n",
    "    probabilities_one_valid = probabilities_valid[:, 1]\n",
    "    auc_roc = roc_auc_score(target_valid,probabilities_one_valid)    \n",
    "    \n",
    "    auc_roc_scores.append(auc_roc)\n",
    "\n",
    "auc_roc_scores = pd.Series(auc_roc_scores)\n",
    "final_score = auc_roc_scores.mean()\n",
    "final_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отличный результат, в качестве бонуса проверим, сможет ли *class_weight = 'balanced'* выдать результат лучше на валидационной выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.5 s, sys: 72 ms, total: 21.6 s\n",
      "Wall time: 21.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6068327227924191"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# <сетка гиперпараметров, по которой будет происходит случайный поиск>\n",
    "param_grid = {\n",
    "    'n_estimators': list(np.arange(2, 101, 2).astype(int)),\n",
    "    'max_depth': [None] + list(np.arange(2, 21,2).astype(int)),\n",
    "    'max_features': ['auto', 'sqrt', None],\n",
    "    'max_leaf_nodes': [None] + list(np.arange(10, 101, 10).astype(int)),\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# <случайный лес к которому будем подбирать параметры>\n",
    "estimator = RandomForestClassifier(random_state = 12345, class_weight = 'balanced')\n",
    "\n",
    "# <модель>\n",
    "model_rf = RandomizedSearchCV(estimator, param_grid, cv=4, scoring = 'f1')\n",
    "\n",
    "# <обучаем модель> \n",
    "model_rf.fit(features_train, target_train)\n",
    "\n",
    "# <среднее значение F1-меры по разным выборкам>\n",
    "model_rf.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нет)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы обучили модели дерева принятия решений, случайного леса и логистической регресии, при обучении применяли кросс-валидацию, а также боролись с дисбалансом классов с помощью апсемплинга. Мы смогли добиться на валидационных выборках нужного нам результата, осталось проверить нашу сильнейшую модель на тестовой выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Тестирование модели <a class=\"anchor\" id=\"4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведем тестирование модели случайного леса (гиперпараметры для которого подбирались с помощью цикла) на тестовой выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.625"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(features_test)\n",
    "\n",
    "f1_score(target_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведем тестирование модели случайного леса (гиперпараметры для которого подбирались случайным поиском) на тестовой выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6360153256704981"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model_rf.predict(features_test)\n",
    "\n",
    "f1_score(target_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Случайный поиск по гиперпараметрам оказался сильнее. Подсчитаем AUC-ROC для обоих моделей. Сначала для первой:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8642080721067309"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities_valid = model.predict_proba(features_test)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "auc_roc = roc_auc_score(target_test,probabilities_one_valid)    \n",
    "    \n",
    "auc_roc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Затем для второй:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8673949001817853"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities_valid = model_rf.predict_proba(features_test)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "auc_roc = roc_auc_score(target_test,probabilities_one_valid)    \n",
    "    \n",
    "auc_roc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ожидаемо вторая модель чуть-чуть сильнее."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы проверили наши сильнейшие модели на тестовой выборке. И они смогли дать высокое значение F1-меры, это хорошо."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
