{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Рекомендация тарифов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В нашем распоряжении данные о поведении клиентов, которые перешли на тарифы из проекта \"Определение перспективного тарифа для телеком компании\". Нужно построить модель для задачи классификации, которая выберет подходящий тариф.\n",
    "\n",
    "Построим модель с максимально большим значением *accuracy*, по крайней мере 0.75."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оглавление:\n",
    "* [1. Откроем и изучим файл](#1)\n",
    "* [2. Разобьем данные на выборки](#2)\n",
    "* [3. Исследуем модели](#3)\n",
    "* [4. Проверим модель на тестовой выборке](#4)\n",
    "* [5. Проверим модели на адекватность](#5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Откроем и изучим файл <a class=\"anchor\" id=\"1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем библиотеки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <импорт библиотеки pandas>\n",
    "import pandas as pd\n",
    "\n",
    "# <импорт библиотеки math>\n",
    "import math\n",
    "\n",
    "# <импорт библиотеки sklearn>\n",
    "import sklearn\n",
    "\n",
    "# <Отключение предупреждений>\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# <импорт библиотеки numpy>\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прочитаем файл с данными."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <чтение файлов с данными с сохранением в различные переменные>\n",
    "df = pd.read_csv('datasets/users_behavior.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим информацию по датафрейму и первые 5 строк:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      "calls       3214 non-null float64\n",
      "minutes     3214 non-null float64\n",
      "messages    3214 non-null float64\n",
      "mb_used     3214 non-null float64\n",
      "is_ultra    3214 non-null int64\n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>311.90</td>\n",
       "      <td>83.0</td>\n",
       "      <td>19915.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>85.0</td>\n",
       "      <td>516.75</td>\n",
       "      <td>56.0</td>\n",
       "      <td>22696.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>77.0</td>\n",
       "      <td>467.66</td>\n",
       "      <td>86.0</td>\n",
       "      <td>21060.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>106.0</td>\n",
       "      <td>745.53</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8437.39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>66.0</td>\n",
       "      <td>418.74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14502.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   calls  minutes  messages   mb_used  is_ultra\n",
       "0   40.0   311.90      83.0  19915.42         0\n",
       "1   85.0   516.75      56.0  22696.96         0\n",
       "2   77.0   467.66      86.0  21060.45         0\n",
       "3  106.0   745.53      81.0   8437.39         1\n",
       "4   66.0   418.74       1.0  14502.75         0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# <рассмотрим датафрейм df>\n",
    "print(df.info())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пропуски отсутствуют."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сменим тип данных на целочисленный, мне кажется в реальных задачах это было бы кстати, например для экономии памяти."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <поменяем тип на целочисленный>\n",
    "df['calls'] = df['calls'].astype('int64')\n",
    "df['messages'] = df['messages'].astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим какой тариф предпочитает большинство пользователей, но вряд ли я смогу это использовать в проекте:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2229\n",
       "1     985\n",
       "Name: is_ultra, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['is_ultra'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подробнее опишем значение каждого атрибута.\n",
    "\n",
    "Таблица *df* (информация о поведении пользователя за месяц):\n",
    "\n",
    "* *сalls* — количество звонков,\n",
    "* *minutes* — суммарная длительность звонков в минутах,\n",
    "* *messages* — количество sms-сообщений,\n",
    "* *mb_used* — израсходованный интернет-трафик в Мб,\n",
    "* *is_ultra* — каким тарифом пользовался в течение месяца («Ультра» — 1, «Смарт» — 0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Данные не нуждаются в предобработке. \n",
    "* Пропуски отсутствуют. \n",
    "* Мы сменили тип данных, и я считаю это верное решение, так как сама суть понятий \"количество звонков\" и \"количество сообщений\" в том что они не дробятся. \n",
    "* Большинство пользователей предпочитают тариф \"Ультра\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Разобьем данные на выборки <a class=\"anchor\" id=\"2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разобьем данные на три выборки: обучающую, валидационную и тестовую. Разобьем их в отношении 3:1:1. Пока нами не была изучена кросс-валидация, использую для этого метод *train_test_split()*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <Импортируем функцию из бибилиотеки sklearn>\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# <Поделим датафрейм на обучающую выборку и выборку, которую позже разделим на валидационную и тестовую.>\n",
    "df_train, df_divide = train_test_split(df, test_size=0.40, random_state=12345)\n",
    "\n",
    "# <Поделим df_divide валидационную и тестовую выборку.>\n",
    "df_valid, df_test = train_test_split(df_divide, test_size=0.50, random_state=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Выборки разделены."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Исследуем модели <a class=\"anchor\" id=\"3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перед исследованием моделей машинного обучения разделим наши датафреймы на целевой признак который нужно предсказать и признаки, которые помогут нам его предсказать:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <Разделим обучающий датафрейм на features и target - целевой признак>\n",
    "features_train = df_train.drop(['is_ultra'], axis=1)\n",
    "target_train = df_train['is_ultra']\n",
    "\n",
    "# <Разделим валидационный датафрейм на features и target - целевой признак>\n",
    "features_valid = df_valid.drop(['is_ultra'], axis=1)  \n",
    "target_valid = df_valid['is_ultra']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Начнем с исследования модели дерева принятия решений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <Импортируем метод дерева принятия решений>\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# <Импортируем метод оценки доли правильных ответов>\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим в цикле долю правильных ответов для разных глубин дерева принятия решений:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth = 2 : 0.7823\n",
      "max_depth = 4 : 0.7854\n",
      "max_depth = 6 : 0.7885\n",
      "max_depth = 8 : 0.7854\n",
      "max_depth = 10 : 0.7807\n",
      "max_depth = 12 : 0.7807\n",
      "max_depth = 14 : 0.7807\n",
      "max_depth = 16 : 0.7807\n",
      "max_depth = 18 : 0.7807\n",
      "max_depth = 20 : 0.7807\n",
      "max_depth = 22 : 0.7807\n",
      "max_depth = 24 : 0.7807\n",
      "max_depth = 26 : 0.7807\n"
     ]
    }
   ],
   "source": [
    "for depth in range(2,27,2):\n",
    "    model = DecisionTreeClassifier(random_state=0, max_depth=depth, min_samples_split= 100)\n",
    "    model.fit(features_train, target_train)\n",
    "    predictions = model.predict(features_valid)\n",
    "    accuracy = accuracy_score(target_valid, predictions)\n",
    "    print('max_depth =',depth,': {:.4f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучшая модель с глубиной 6 с *accuracy* = 0.7885. *min_samples_split*  был подобран интуитивно, и улучшил результат на 6 тысячных по сравнению с дефолтным. Любые опыты с критерием и весом классов (*balanced*) ухудшали результат при *min_samples_split* = 100."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перейдем к алгоритму случайного леса:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <Импортируем алгоритм случайного леса>\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим в цикле долю правильных ответов для разного количества оценщиков:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 2 : 0.7776\n",
      "n_estimators = 3 : 0.7900\n",
      "n_estimators = 4 : 0.7916\n",
      "n_estimators = 5 : 0.7947\n",
      "n_estimators = 6 : 0.7947\n",
      "n_estimators = 7 : 0.7916\n",
      "n_estimators = 8 : 0.7900\n",
      "n_estimators = 9 : 0.7947\n",
      "n_estimators = 10 : 0.8009\n",
      "n_estimators = 11 : 0.7994\n",
      "n_estimators = 12 : 0.8056\n",
      "n_estimators = 13 : 0.8040\n",
      "n_estimators = 14 : 0.8009\n",
      "n_estimators = 15 : 0.8025\n"
     ]
    }
   ],
   "source": [
    "for estimators in range(2,16):\n",
    "    model = RandomForestClassifier(random_state=8897, n_estimators=estimators, max_depth=6)\n",
    "    model.fit(features_train, target_train)\n",
    "    predictions = model.predict(features_valid)\n",
    "    accuracy = accuracy_score(target_valid, predictions)\n",
    "    print('n_estimators =',estimators,': {:.4f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучшая модель с количеством оценщиков 12 и глубиной 6 с *accuracy* = 0.8056. *min_samples_split* лучше оставить дефолтным, он ухудшал результат."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем использовать *RandomizedSearchCV* для подбора параметров модели случайного леса, проверим модель выше и эту на тестовой выборке в следующем пункте. Я слышал что использование таких методов не рекомендуется в проекте без понимания того что в них происходит, поэтому постараюсь разъяснить что я понял, исследуя код:\n",
    "\n",
    "* *param_grid* это словарь в котором указываются гиперпараметры и интервалы в которых они могут находится, или в случае если это категориальные признаки - возможные значения.\n",
    "* функция *np.linspace()* последовательность чисел, количество - третий аргумент, сами числа от первого аргумента до второго. Если у нее два аргумента, выдает 50 чисел от первого аргумента до второго.\n",
    "* в *np.arange* в качестве третьего аргумента шаг. Первый и второй аргумент - начало и конец последовательности. np.arange(0.5, 1, 0.1) - тут в последовательности не будет единицы но будет [0.5, 0.6, 0.7, 0.8, 0.9].\n",
    "* *max_leaf_nodes* - максимальное количество листовых узлов (нижние узлы с ответами).\n",
    "* *max_features* - количеcтво используемых признаков.\n",
    "* *min_samples_split* - минимальное число объектов, при котором выполняется расщепление на узлы.\n",
    "* *bootstrap* - Бутстрэп-агрегирование или бэггинг, алгоритм предназначенный для улучшения стабильности и точности алгоритмов машинного обучения, также уменьшает дисперсию и помогает избежать переобучения. Для меня - черный ящик."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "                   estimator=RandomForestClassifier(bootstrap=True,\n",
       "                                                    class_weight=None,\n",
       "                                                    criterion='gini',\n",
       "                                                    max_depth=None,\n",
       "                                                    max_features='auto',\n",
       "                                                    max_leaf_nodes=None,\n",
       "                                                    min_impurity_decrease=0.0,\n",
       "                                                    min_impurity_split=None,\n",
       "                                                    min_samples_leaf=1,\n",
       "                                                    min_samples_split=2,\n",
       "                                                    min_weight_fraction_leaf=0.0,\n",
       "                                                    n_estimators='warn',\n",
       "                                                    n_jobs=None,\n",
       "                                                    o...\n",
       "                                                           11, 11, 11, 11, 11,\n",
       "                                                           11, 11, 11, 11, 11,\n",
       "                                                           11, 12, 12, 12, 12, ...],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': array([  2,   4,   6,   8,  10,  12,  14,  16,  18,  20,  22,  24,  26,\n",
       "        28,  30,  32,  34,  36,  38,  40,  42,  44,  46,  48,  50,  52,\n",
       "        54,  56,  58,  60,  62,  64,  66,  68,  70,  72,  74,  76,  78,\n",
       "        80,  82,  84,  86,  88,  90,  92,  94,  96,  98, 100])},\n",
       "                   pre_dispatch='2*n_jobs', random_state=8897, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# <Импортируем алгоритм случайного поиска по гиперпараметрам>\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# <сетка гиперпараметров, по которой будет происходит случайный поиск>\n",
    "param_grid = {\n",
    "    'n_estimators': np.linspace(2, 100).astype(int),\n",
    "    'max_depth': [None] + list(np.linspace(2, 10).astype(int)),\n",
    "    'max_features': ['auto', 'sqrt', None] + list(np.arange(0, 5, 1)),\n",
    "    'max_leaf_nodes': [None] + list(np.linspace(10, 50, 500).astype(int)),\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# <случайный лес к которому будем подбирать параметры>\n",
    "estimator = RandomForestClassifier(random_state = 8897)\n",
    "\n",
    "# <модель>\n",
    "rs = RandomizedSearchCV(estimator, param_grid, random_state=8897)\n",
    "\n",
    "# <обучаем модель> \n",
    "rs.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 38,\n",
       " 'min_samples_split': 2,\n",
       " 'max_leaf_nodes': 44,\n",
       " 'max_features': 'auto',\n",
       " 'max_depth': 8,\n",
       " 'bootstrap': True}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# <набор параметров, которые подобрал случайный поиск.>\n",
    "rs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7993779160186625"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# <предскажем целевой признак и подсчитаем долю правильных ответов.>\n",
    "predictions = rs.predict(features_valid)\n",
    "accuracy = accuracy_score(target_valid, predictions)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат хуже, но тем не менее проверим эту модель на тестовой выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перейдем к логистической регрессии:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <Импортируем метод логистической регрессии>\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7589424572317263"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# <Создадим модель лог. регрессии,>\n",
    "model = LogisticRegression(random_state=12345)\n",
    "\n",
    "# <обучим ее,>\n",
    "model.fit(features_train, target_train)\n",
    "\n",
    "# <предскажем целевой признак,>\n",
    "predictions = model.predict(features_valid)\n",
    "\n",
    "# <и подсчитаем долю правильных ответов.>\n",
    "accuracy = accuracy_score(target_valid, predictions)\n",
    "\n",
    "# <выведем долю правильных ответов>\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат хуже чем у модели случайного леса или просто решающего дерева. Я осмотрел некоторые гиперпараметры типа *solver*, *class_weight*, *max_iter* и попробовал покрутить их, но они или давали тот же самый результат или еще сильней ухудшали его (использовал например советы отсюда https://overcoder.net/q/968297/%D0%BA%D0%B0%D0%BA-%D0%BF%D0%BE%D0%B2%D1%8B%D1%81%D0%B8%D1%82%D1%8C-%D1%82%D0%BE%D1%87%D0%BD%D0%BE%D1%81%D1%82%D1%8C-%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D0%B8-%D0%BB%D0%BE%D0%B3%D0%B8%D1%81%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%BE%D0%B9-%D1%80%D0%B5%D0%B3%D1%80%D0%B5%D1%81%D1%81%D0%B8%D0%B8-%D0%B2-python-scikit)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Мы разделили тренировочную выборку и валидационную на признаки(features) и целевой признак(target).\n",
    "* Обучили дерево принятия решений и выбрали лучшие с максимальной глубиной 2 и 6.\n",
    "* Обучили модель случайного леса, и выбрали лучшую с количеством оценщиков 12 и глубиной 6. Ее используем для проверки на тестовой выборке. Также используем модель, для которой подобрали параметры случайным поиском.\n",
    "* Обучили модель логистической регресии и получили метрики хуже чем у предыдущих моделей.\n",
    "* Открыли для себя несколько интересных методов, гиперпараметров, потренировались подбирать параметры."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Проверим модель на тестовой выборке <a class=\"anchor\" id=\"4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перед проверкой модели разделим наш тестовый датафрейм на features и target:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <Разделим тестовый датафрейм на features и target - целевой признак>\n",
    "features_test = df_test.drop(['is_ultra'], axis=1)  \n",
    "target_test = df_test['is_ultra']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим модель на тестовой выборке:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.7994\n"
     ]
    }
   ],
   "source": [
    "# <Создадим модель случайного леса,>\n",
    "model = RandomForestClassifier(random_state=8897, n_estimators=12, max_depth=6)\n",
    "\n",
    "# <обучим ее,>\n",
    "model.fit(features_train, target_train)\n",
    "\n",
    "# <предскажем целевой признак,>\n",
    "predictions = model.predict(features_test)\n",
    "\n",
    "# <и подсчитаем долю правильных ответов.>\n",
    "accuracy = accuracy_score(target_test, predictions)\n",
    "\n",
    "# <выведем долю правильных ответов>\n",
    "print('accuracy =','{:.4f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим модель *rs* с гиперпараметрами, подобранными случайным поиском на тестовой выборке:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.8056\n"
     ]
    }
   ],
   "source": [
    "# <предскажем целевой признак,>\n",
    "predictions = rs.predict(features_test)\n",
    "\n",
    "# <и подсчитаем долю правильных ответов.>\n",
    "accuracy = accuracy_score(target_test, predictions)\n",
    "\n",
    "# <выведем долю правильных ответов>\n",
    "print('accuracy =','{:.4f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель, для которой мы подбирали гиперпараметры случайным поиском показала чуть-чуть лучший результат, чем та у которой мы подобрали только глубину и количество оценщиков. Тем не менее обе модели справились с поставленной задачей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Мы проверили две лучшие подобранные нами модели на тестовой выборке и получили устраивающий нас результат.\n",
    "* Следующий шаг: научиться пользоваться кросс-валидацией и GridSearch для повышения accuracy в подобных задачах."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. (бонус) Проверьте модели на адекватность <a class=\"anchor\" id=\"5\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для проверки адекватности нашей модели напишем модель (функцию), предсказывающую значение признака *is_ultra* самым простым и тупорылым способом, 50 на 50, и сравним, лучше ли наша модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.4961\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random_predictions = np.random.randint(low = 0, high = 2, size = 643) \n",
    "\n",
    "# <подсчитаем долю правильных ответов.>\n",
    "accuracy = accuracy_score(target_test, random_predictions)\n",
    "\n",
    "# <выведем долю правильных ответов>\n",
    "print('accuracy =','{:.4f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим случайные ответы ошибаются примерно в 50% случаев. Наша модель ошибается реже - только лишь в 19.44% случаев."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Наша модель лучше, чем подкидывание монетки. Она прошла проверку на адекватность/вменяемость."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
